# Graph-Based NLP

In this series of works we revisit classical natural language processing tasks by casting them as tasks defined on graphs, allowing the use of graph neural networks (GNN) to address them. 

## Contributions

In one research direction, we've proposed a graph-based approach to document classification, using a hierarchical GNN operating in the hyperbolic space ; we've also proposed a GNN-RNN architecture for extractive document summarization (presented at ECIR 2024). In another research direction, we have highlighted the capacity of pre-trained language models to linearly encode the structure of AMR (abstract meaning representation) graphs in the attention mechanism (presented at *SEM 2024). 

### Selected Publications
- [Interactive Document Summarization with GNN-RNN](publications/ecir2024.pdf) by Raoufdine Said, Adrien Guille. *European Conference on Information Retrieval (ECIR)*, 2024 - **Core A**
- [Exploring Semantics in Pretrained Language Model Attention]() by Frédéric Charpentier, Jairo Cugliari, Adrien Guille. *13th Joint Conference on Lexical and Computational Semantics, co-located with NAACL (StarSEM @ NAACL)*, 2024
- [Classification de documents par un réseau de neurones opérant sur des graphes dans l'espace hyperbolique](publications/egc_hhgnn.pdf) by Adrien Guille, Hugo Attali. *Conférence sur l'Extraction et la Gestion des Connaissances (EGC)*, 2023
- [Document Classification with Hierarchical Graph Neural Networks](publications/docgat.pdf) by Adrien Guille, Hugo Attali. *18th International Workshop on Mining and Learning with Graphs (MLG @ ECML-PKDD)*, 2022

### Code
- Interactive Document Summarization with GNN-RNN: [https://github.com/Baragouine/radsum]
- Exploring Semantics in Pretrained Language Model Attention: [https://anonymous.4open.science/r/sem_LM_att-322F/]
