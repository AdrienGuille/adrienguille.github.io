# Teaching

## Representation Learning for NLP (Master Machine Learning & AI @ U Lyon 2)

Here is a list of suggested readings for this course:

### Pre-Trained Word Representations

#### Main techniques to learn vector space representations of words

- SGNS: [Distributed Representations of Words and Phrases and their Compositionality](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)
- Glove: [Global Vectors for Word Representation](https://nlp.stanford.edu/pubs/glove.pdf)
- Link between SGNS, GloVe & PMI: [Neural Word Embedding as Implicit Matrix Factorization](https://papers.nips.cc/paper/5477-neural-word-embedding-as-implicit-matrix-factorization.pdf)

### Supervised Learning with Pre-Trained Word Representations

#### Main neural architectures to solve document-level classification tasks 

- CNN: [Convolutional Neural Networks for Sentence Classification](https://arxiv.org/pdf/1408.5882.pdf)
- RNN & GRU: [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](https://arxiv.org/pdf/1406.1078.pdf)

#### Sequence to Sequence learning and attention mechanism

- Seq2Seq: [Sequence to Sequence Learning with Neural Networks](https://papers.nips.cc/paper/2014/file/a14ac55a4f27472c5d894ec1c3c743d2-Paper.pdf)
- Dot-product Attention: [Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/pdf/1508.04025.pdf)
- Transformer: [Attention is All You Need](https://arxiv.org/pdf/1706.03762.pdf)

### Supervised Learning with Pre-Trained Language Models

- BERT: [Bidirectional Encoder Representations from Transformers](https://arxiv.org/pdf/1810.04805.pdf)

## Machine Learning with Graphs (Master Complex Systems @ ENS Lyon)

Here is a list of suggested readings for this course:

### Pre-trained Node and Graph Representations

- DeepWalk: [Online Learning of Social Representations](https://arxiv.org/pdf/1403.6652)
- Node2Vec: [Scalable Feature Learning for Networks](https://cs.stanford.edu/~jure/pubs/node2vec-kdd16.pdf)

### Graph Neural Networks

- GCN: [Semi Supervised Node Classification with Graph Convolutional Networks](https://arxiv.org/pdf/1609.02907.pdf)
- GAT: [Graph Attention Networks](https://arxiv.org/pdf/1710.10903.pdf)
